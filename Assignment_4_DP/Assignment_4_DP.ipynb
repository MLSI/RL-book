{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Manual Value Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initialize Value Function: $v_0(s_1) = 10, v_0(s_2)=1, v_0(s_3)$.\n",
    "- Iteration 1: \n",
    "\n",
    "$$\\begin{aligned}\n",
    "q_1(s_1, a_1) &= 8 +0.2*10+0.6*1+0=10.6\\\\\n",
    "q_1(s_1, a_2) &= 10 +0.1*10+0.2*1+0=11.2\\\\\n",
    "v_1(s_1) &= max(10.6, 11.2) = 11.2\\\\\n",
    "\\pi_1(s_1) &= a_2\n",
    "\\end{aligned}$$\n",
    "\n",
    "$$\\begin{aligned}\n",
    "q_1(s_2, a_1) &= 1 +0.3*10+0.3*1+0=4.3\\\\\n",
    "q_1(s_2, a_2) &= -1 +0.5*10+0.3*1+0=4.3\\\\\n",
    "v_1(s_2) &= max(4.3, 4.3) = 4.3\\\\\n",
    "\\pi_1(s_2) &= a_1\n",
    "\\end{aligned}$$\n",
    "\n",
    "- Iteration 2:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "q_2(s_1, a_1) &= 8 +0.2*11.2+0.6*4.3+0=12.82\\\\\n",
    "q_2(s_1, a_2) &= 10 +0.1*11.2+0.2*4.3+0=11.98\\\\\n",
    "v_2(s_1) &= max(12.82, 11.98) = 12.82\\\\\n",
    "\\pi_2(s_1) &= a_1\n",
    "\\end{aligned}$$\n",
    "\n",
    "$$\\begin{aligned}\n",
    "q_2(s_2, a_1) &= 1 +0.3*11.2+0.3*4.3+0=5.65\\\\\n",
    "q_2(s_2, a_2) &= -1 +0.5*11.2+0.3*4.3+0=5.89\\\\\n",
    "v_2(s_2) &= max(5.65,5.89) =5.89\\\\\n",
    "\\pi_2(s_2) &= a_2\n",
    "\\end{aligned}$$\n",
    "\n",
    "- Why only needs k=2:\n",
    "$$\\begin{aligned}\n",
    "q_k(s_1, a_1) - q_k(s_1, a_2) &= 8-10 + (0.2-0.1)v_{k-1}(s_1)+ (0.6-0.2)v_{k-1}(s_2)\\\\\n",
    "&= -2 + 0.1v_{k-1}(s_1)+ 0.4 v_{k-1}(s_2) ~ \\text{for all } k\\geq 1\\\\\n",
    "q_k(s_2, a_1) - q_k(s_2, a_2) &= 1-(-1) + (0.3-0.5)v_{k-1}(s_1)+ (0.3-0.3)v_{k-1}(s_2)\\\\\n",
    "&= 2 -0.2v_{k-1}(s_1) ~ \\text{for all } k\\geq 1\n",
    "\\end{aligned}$$\n",
    "\n",
    "Since $v_k(s_1) \\geq 12.82$ and $v_k(s_2) \\geq 5.89$ for all $k \\geq 3$, we have\n",
    "$$\\begin{aligned}\n",
    "q_k(s_1, a_1) - q_k(s_1, a_2) \\geq -2 + 0.1*12.82+ 0.4 *5.89 = 1.638 >0 ~ \\text{for all } k\\geq 3\\\\\n",
    "q_k(s_2, a_1) - q_k(s_2, a_2) \\leq 2 -0.2*12.82 = -0.56 <0  ~ \\text{for all } k\\geq 3\n",
    "\\end{aligned}$$\n",
    "\n",
    "Hence $q_k(s_1, a_1) >q_k(s_1, a_2)$ and  $q_k(s_2, a_2) >q_k(s_2, a_1)$ for all $k\\geq 3$. Therefore we have $\\pi_k(s_1) = a_1$ and $\\pi_k(s_2) = a_2$ for all $k\\geq3$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Frog Croaking revisited\n",
    "\n",
    "(refer back to Q3 on Assignment 3)\n",
    "\n",
    "Task: \n",
    "- Compute Optimal Value Function and Optimal Policy Using Policy Iteration Algorithm & Value Iteration Algorithm;  - Analyze computational efficiency in terms of speed of convergence to the optimal value function. \n",
    "- How do those 2 iteration methods compare with brute force method of evaluating MDP for $2^{n-1}$ determimistic policy in previous assignment?\n",
    "- Plot graphs of convergence for different values of n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path\n",
    "sys.path.append('/Users/mulingsi/Desktop/MSE346/RL-book/')\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Dict\n",
    "from rl.markov_decision_process import FiniteMarkovDecisionProcess\n",
    "from rl.markov_decision_process import FinitePolicy, StateActionMapping\n",
    "from rl.markov_process import FiniteMarkovProcess, FiniteMarkovRewardProcess\n",
    "from rl.distribution import Categorical, Constant\n",
    "from scipy.stats import poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class LilypadState:\n",
    "    lilypad: int\n",
    "        \n",
    "LilypadSoundMapping = StateActionMapping[LilypadState, str]\n",
    "\n",
    "class FrogEscapeMDP(FiniteMarkovDecisionProcess[LilypadState, str]):\n",
    "    \n",
    "    def __init__(self, num_lilypads:int):\n",
    "        self.num_lilypads = num_lilypads \n",
    "        super().__init__(self.get_action_transition_reward_map())\n",
    "\n",
    "    def get_action_transition_reward_map(self) -> LilypadSoundMapping:\n",
    "        d: Dict[LilypadState, Dict[str, Categorical[Tuple[LilypadState,float]]]] = {}\n",
    "            \n",
    "        d[0] = None\n",
    "        d[self.num_lilypads] = None\n",
    "        \n",
    "        for lilypad in range(1,self.num_lilypads):\n",
    "            state: LilypadState = LilypadState(lilypad)\n",
    "            d1: Dict[str,Categorical[Tuple[LilypadState, float]]] = {}\n",
    "\n",
    "            # sound A\n",
    "            sr_probs_dict_a: Dict[Tuple[LilypadState, float], float] = {}\n",
    "            sr_probs_dict_a[(LilypadState(lilypad - 1), 0)] = lilypad / (self.num_lilypads)\n",
    "            if lilypad + 1 == self.num_lilypads:\n",
    "                sr_probs_dict_a[(LilypadState(lilypad + 1), 1)] = 1 - lilypad/(self.num_lilypads)\n",
    "            else:\n",
    "                sr_probs_dict_a[(LilypadState(lilypad + 1), 0)] = 1 - lilypad /(self.num_lilypads)\n",
    "            d1['A'] = Categorical(sr_probs_dict_a)\n",
    "\n",
    "            # sound B\n",
    "            sr_probs_dict_b: Dict[Tuple[LilypadState, float], float] = {}\n",
    "            for i in range(self.num_lilypads+1):\n",
    "                if i != lilypad:\n",
    "                    if i == self.num_lilypads :\n",
    "                        sr_probs_dict_b[(LilypadState(i), 1)] = 1/(self.num_lilypads)\n",
    "                    else:\n",
    "                        sr_probs_dict_b[(LilypadState(i), 0)] = 1 /(self.num_lilypads)\n",
    "            d1['B'] = Categorical(sr_probs_dict_b)\n",
    "\n",
    "            d[state] = d1\n",
    "        return d\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    from pprint import pprint\n",
    "    number_of_lilypads: int = 10\n",
    "    frog_mdp: FrogEscapeMDP = FrogEscapeMDP(number_of_lilypads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDP Value Iteration Optimal Value Function and Optimal Policy\n",
      "--------------\n",
      "{LilypadState(lilypad=1): 0.6724805984784683,\n",
      " LilypadState(lilypad=2): 0.6991250841449133,\n",
      " LilypadState(lilypad=3): 0.7057979809066267,\n",
      " LilypadState(lilypad=4): 0.7086717998967249,\n",
      " LilypadState(lilypad=5): 0.7106042389439681,\n",
      " LilypadState(lilypad=6): 0.7125566471110998,\n",
      " LilypadState(lilypad=7): 0.7155102249572595,\n",
      " LilypadState(lilypad=8): 0.7224350065438307,\n",
      " LilypadState(lilypad=9): 0.7501827365659701}\n",
      "For State LilypadState(lilypad=1):\n",
      "  Do Action B with Probability 1.000\n",
      "For State LilypadState(lilypad=2):\n",
      "  Do Action A with Probability 1.000\n",
      "For State LilypadState(lilypad=3):\n",
      "  Do Action A with Probability 1.000\n",
      "For State LilypadState(lilypad=4):\n",
      "  Do Action A with Probability 1.000\n",
      "For State LilypadState(lilypad=5):\n",
      "  Do Action A with Probability 1.000\n",
      "For State LilypadState(lilypad=6):\n",
      "  Do Action A with Probability 1.000\n",
      "For State LilypadState(lilypad=7):\n",
      "  Do Action A with Probability 1.000\n",
      "For State LilypadState(lilypad=8):\n",
      "  Do Action A with Probability 1.000\n",
      "For State LilypadState(lilypad=9):\n",
      "  Do Action A with Probability 1.000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from rl.dynamic_programming import value_iteration_result\n",
    "\n",
    "print(\"MDP Value Iteration Optimal Value Function and Optimal Policy\")\n",
    "print(\"--------------\")\n",
    "opt_vf_vi, opt_policy_vi = value_iteration_result(frog_mdp, gamma=1)\n",
    "pprint(opt_vf_vi)\n",
    "print(opt_policy_vi)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Job-Hopping and Wages-Utility-Maximization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4: 2-stores inventory control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-book",
   "language": "python",
   "name": "rl-book"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
